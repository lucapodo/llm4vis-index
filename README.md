# LLM4Vis index

* [LLM4VIS Introduction](#llm4vis-introduction) üìù
* [LLM4VIS: Difference between the Two Approaches with and without the Wrapper](#llm4vis-difference-between-the-two-approaches-with-and-without-the-wrapper) üîÑ
* [LLM4VIS hypercube](#llm4vis-hypercube) üìä
* [LLM4VIS index contents](#llm4vis-index-contents) üìö
    * [Tools](#tools) üîß
    * [Research Paper](#research-paper) üìÑ
    * [Models](#models) ü§ñ
    * [Framework](#framework) üõ†Ô∏è
    * [Dataset](#dataset) üì¶
    * [Benchmark and Guidance](#benchmark-and-guidance) üìà
* [Submit Your Work](#submit-your-work) üì•
* [Citation and Contribution](#citation-and-contribution) üîñ

## LLM4VIS Introduction

[Insert introduction to LLM4VIS here]

## Large Language Model as Data Scientists approaches: From Pure LLM strategy to hybrid one

In the realm of data science, Language Models (LMs) have emerged as powerful tools for various tasks, both as standalone entities and in conjunction with coding environments like Python. Here's a brief overview of what can be achieved using LMs in both scenarios:

- **Pure LLM Approach**: LLMs can sift through large volumes of textual data, extracting key insights, trends, and patterns without the need for additional agents or components.
- **LLMs with Code Environment Integration**: LLMs can generate code snippets for tasks like data cleaning, transformation, and normalization, which can then be executed within a coding environment to prepare data for analysis.

![Alt text](pure.svg "Pure approach")
![Alt text](hybrid.svg "Hybrid approach")

## LLM4VIS hypercube dimensions
An LLM4VIS methodology can be delineated by a hypercube comprising the following dimensions:
1. **Learning Strategy (Fine-tuning/Few-zero-shot learning)**: This dimension defines the methodology used for model training.
2. **Task-Agnosticism**: This dimension assesses whether the model's input encompasses only the dataset or incorporates user utterances.
3. **Approach**: This dimension distinguishes between a pure LLM approach and one enriched with additional tools or methodologies.
4. **Output Explainability**: This dimension determines whether the model merely provides a visualization or includes a narrative to elucidate the reasoning strategy.
5. **Effort**: This dimension quantifies the computational and strategic effort required to generate the output.

By leveraging these dimensions, it becomes feasible to categorize and evaluate all proposed approaches in the literature, providing a comprehensive overview of the current state-of-the-art in this domain.

## LLM4VIS index contents
[Add introduction to the content sections. Describe each dimension]
- Tools: [what it contains]
- Research Paper: ... 
- Models: ...
- Framework: ...
- Dataset: ...
- Benchmark and Guidance: ...

### Tools
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| (PandasAI)[https://github.com/Sinaptik-AI/pandas-ai] | PandasAI is designed to be used in conjunction with pandas. It makes pandas conversational, allowing you to ask questions to your data in natural language | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |


### Research Paper
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| Example1 | Description of Example1 | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |

### Models
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| Example1 | Description of Example1 | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |

### Frameworks
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| Example1 | Description of Example1 | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |

### Datasets
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| Example1 | Description of Example1 | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |

### Benchmarks and Guidance
| Name | Description | Classification Based on Hypercube |
| ----------------- | ----------- | ---------------------------------- |
| Example1 | Description of Example1 | Classification1 |
| Example2 | Description of Example2 | Classification2 |
| Example3 | Description of Example3 | Classification1 |

## Submit Your Work

If you would like your work to be indexed in this repository, please submit it to us by clicking the button below.
[Submit Your Work](#) [![Submit](https://img.shields.io/badge/Submit-Your_Work-green)](#) 

## Citation and Contribution

To cite this repository in publications, please use the following Bibtex entry:
```bibtex
@misc{llm4vis_repository,
  author       = {Your Name},
  title        = {LLM4VIS Repository},
  year         = {Year},
  publisher    = {GitHub},
  journal      = {GitHub Repository},
  howpublished = {\url{https://github.com/lucapodo/llm4vis-index}},
}
